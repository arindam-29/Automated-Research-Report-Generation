{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ee1ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/arindam/Machine Learning/GenAI_2025/AgenticAI/9_Automated-Research-Report-Generation'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0818a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added to path: /Users/arindam/Machine Learning/GenAI_2025\n"
     ]
    }
   ],
   "source": [
    "# Get project root — one level up from 'research_and_analyst'\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"Project root added to path:\", project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7efe453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research_and_analyst.utils.model_loader import ModelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e55ff63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-11-10T02:45:10.074051Z\", \"level\": \"info\", \"event\": \"Initializing ApiKeyManager\"}\n",
      "{\"timestamp\": \"2025-11-10T02:45:10.074387Z\", \"level\": \"info\", \"event\": \"OPENAI_API_KEY loaded successfully from environment\"}\n",
      "{\"timestamp\": \"2025-11-10T02:45:10.074666Z\", \"level\": \"info\", \"event\": \"GOOGLE_API_KEY loaded successfully from environment\"}\n",
      "{\"timestamp\": \"2025-11-10T02:45:10.075043Z\", \"level\": \"info\", \"event\": \"GROQ_API_KEY loaded successfully from environment\"}\n",
      "{\"path\": \"/Users/arindam/Machine Learning/GenAI_2025/AgenticAI/9_Automated-Research-Report-Generation/research_and_analyst/config/configuration.yaml\", \"keys\": [\"astra_db\", \"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-10T02:45:10.076547Z\", \"level\": \"info\", \"event\": \"Configuration loaded successfully\"}\n",
      "{\"config_keys\": [\"astra_db\", \"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-10T02:45:10.076732Z\", \"level\": \"info\", \"event\": \"YAML configuration loaded successfully\"}\n"
     ]
    }
   ],
   "source": [
    "model_loader = ModelLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b3e9305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"provider_key\": \"openai\", \"timestamp\": \"2025-11-10T02:45:10.079987Z\", \"level\": \"info\", \"event\": \"LLM Provider Selected\"}\n",
      "{\"provider\": \"openai\", \"model\": \"gpt-5-nano\", \"timestamp\": \"2025-11-10T02:45:10.080319Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"provider\": \"openai\", \"model\": \"gpt-5-nano\", \"timestamp\": \"2025-11-10T02:45:10.222938Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n"
     ]
    }
   ],
   "source": [
    "llm=model_loader.load_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d585280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi! Nice to meet you. What would you like help with today? I can explain ideas, answer questions, brainstorm, draft text, help with coding, summarize content, plan things, or just chat. Tell me what you’re aiming for, or ask me anything.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91769b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a9b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import AIMessage,HumanMessage , SystemMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b0d1dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyst(BaseModel):\n",
    "    name: str = Field(description=\"Name of the analyst.\")\n",
    "    role: str = Field(description=\"Role of the analyst in the context of the topic.\")\n",
    "    affiliation: str = Field(description=\"Primary affiliation of the analyst.\")\n",
    "    description: str = Field(description=\"Description of the analyst focus, concerns, and motives.\")\n",
    "    \n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36ad0f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst = Analyst(\n",
    "    name=\"Arindam Choudhury\",\n",
    "    role=\"genai eng\",\n",
    "    affiliation=\"Personal AI Research LAB\",\n",
    "    description=\"I am genai developer as well as mentor\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e9ba7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arindam Choudhury\n",
      "genai eng\n",
      "Personal AI Research LAB\n"
     ]
    }
   ],
   "source": [
    "print(analyst.name)\n",
    "print(analyst.role)\n",
    "print(analyst.affiliation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05f5b7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Arindam Choudhury\n",
      "Role: genai eng\n",
      "Affiliation: Personal AI Research LAB\n",
      "Description: I am genai developer as well as mentor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(analyst.persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "208c2dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perspectives(BaseModel):\n",
    "       analysts: List[Analyst] = Field(description=\"Comprehensive list of analysts with their roles and affiliations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5dd3992",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnalystsState(TypedDict):\n",
    "    topic: str #research topic\n",
    "    max_analysts: int # number of analyst\n",
    "    human_analyst_feedback: str # Human feedback\n",
    "    analysts: List[Analyst] # Analyst asking questions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9ea018f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'finance',\n",
       " 'max_analysts': 5,\n",
       " 'human_analyst_feedback': 'give the real info'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GenerateAnalystsState(\n",
    "    topic = \"finance\",\n",
    "    max_analysts= 5,\n",
    "    human_analyst_feedback= \"give the real info\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70ffa4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_instructions=\"\"\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\n",
    "\n",
    "1. First, review the research topic:\n",
    "{topic}\n",
    "        \n",
    "2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts: \n",
    "        \n",
    "{human_analyst_feedback}\n",
    "    \n",
    "3. Determine the most interesting themes based upon documents and / or feedback above.\n",
    "                    \n",
    "4. Pick the top {max_analysts} themes.\n",
    "\n",
    "5. Assign one analyst to each theme.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae9b3672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\\n\\n1. First, review the research topic:\\neducation\\n\\n2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts: \\n\\nplease exaplain only on AI\\n\\n3. Determine the most interesting themes based upon documents and / or feedback above.\\n\\n4. Pick the top 4 themes.\\n\\n5. Assign one analyst to each theme.', 'Generate the set of analysts.']\n"
     ]
    }
   ],
   "source": [
    "print([analyst_instructions.format(\n",
    "        topic=\"education\",\n",
    "        max_analysts=4,\n",
    "        human_analyst_feedback=\"please exaplain only on AI\"\n",
    "        \n",
    "        )] + [\"Generate the set of analysts.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39e7d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analyst(state:GenerateAnalystsState):\n",
    "    \"\"\"\n",
    "    it is creating my analyst\n",
    "    \n",
    "    \"\"\"\n",
    "    topic = state[\"topic\"]\n",
    "    max_analysts = state[\"max_analysts\"]\n",
    "    human_analyst_feedback = state.get(\"human_analyst_feedback\",\"\")\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(Perspectives)\n",
    "    \n",
    "    system_messages = analyst_instructions.format(\n",
    "        topic=topic,\n",
    "        max_analysts=max_analysts,\n",
    "        human_analyst_feedback=human_analyst_feedback\n",
    "        \n",
    "        )\n",
    "    analysts = structured_llm.invoke([SystemMessage(content=system_messages)] + [HumanMessage(content=\"Generate the set of analysts.\")])\n",
    "    \n",
    "    # Write the list of analysis to state\n",
    "    return {\"analysts\": analysts.analysts}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44d0a2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'analysts': [Analyst(name='Jordan Park', role='Senior Sales Enablement & Performance Analytics Lead', affiliation='MarketEdge Analytics', description='Theme: Sales process optimization and technology enablement. Focuses on designing efficient sales workflows, coaching and training programs, KPI design and dashboards, CRM/tooling adoption, and measuring ROI of enablement initiatives. Aims to shorten ramp time, improve win rates, and harmonize human skills with AI-assisted selling, while ensuring data quality and user adoption.'),\n",
       "  Analyst(name='Dr. Maya Chen', role='Ethics & Compliance Analyst for Sales & AI', affiliation='Center for Responsible Sales', description='Theme: Ethics, regulatory compliance, and agent well-being in sales. Examines data privacy and governance (GDPR/CCPA), telemarketing and consent rules (TCPA), call recording and transparency, fair compensation and workload management, burnout risk, and governance of AI usage in sales processes. Develops frameworks for responsible monitoring, customer-centric practices, and risk mitigation.')]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_analyst(\n",
    "    {'topic': 'Sales Agent',\n",
    "    'max_analysts': 2,\n",
    "    'human_analyst_feedback': 'give the real info'}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acbd701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_feedback(state):\n",
    "    \"\"\" No-op node that should be interrupted on \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2abcfccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    feedback = (state.get(\"human_analyst_feedback\") or \"\").strip().lower()\n",
    "    if feedback and feedback not in [\"\", \"none\", \"skip\", \"done\", \"continue\"]:\n",
    "        return \"create_analyst\"\n",
    "    return END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4aef85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def should_continue(state):\n",
    "#     \"\"\" Return the next node to execute \"\"\"\n",
    "#     human_analyst_feedback = state.get(\"human_analyst_feedback\",None)\n",
    "#     if human_analyst_feedback:\n",
    "#         return \"create_analyst\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a7596bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e942924",
   "metadata": {},
   "source": [
    "## First Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69a8b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(GenerateAnalystsState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "914c955f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11627a410>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_node(\"create_analyst\",create_analyst)\n",
    "builder.add_node(\"human_feedback\", human_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd30a26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11627a410>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_edge(START,\"create_analyst\")\n",
    "builder.add_edge(\"create_analyst\", \"human_feedback\")\n",
    "builder.add_conditional_edges(\"human_feedback\",\n",
    "                        should_continue,\n",
    "                        [\"create_analyst\",\n",
    "                        END])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a60c6891",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73530c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile(interrupt_before= [\"human_feedback\"],checkpointer= memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37a56840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6bd1fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"the benefits of adopting Langgraph as an agent framework\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca5b3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_analysts = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e3850f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread =  {\"configurable\":{\"thread_id\":1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe662e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Dr. Maya Chen\n",
      "Affiliation: LangTech Labs\n",
      "Role: Senior AI Architecture Analyst (Modularity & Interoperability)\n",
      "Description: Focuses on how Langgraph enables modular, pluggable agents and cross-domain interoperability. Evaluates component reusability, standardized interfaces, and developer experience. Motives: accelerate prototyping, reduce integration friction, and foster a healthy plugin ecosystem. Key concerns include plugin quality, versioning, security of third‑party components, and interface stability to prevent fragmentation.\n",
      "--------------------------------------------------\n",
      "Name: Prof. Luis Nakamura\n",
      "Affiliation: Center for AI Policy & Safety\n",
      "Role: Governance & Safety Analyst (Scalability & Observability)\n",
      "Description: Assesses Langgraph's scalability, multi‑agent coordination, observability, auditability, and policy enforcement in enterprise settings. Focuses on governance, traceability of decisions, reproducibility, and regulatory compliance. Motives: guide safe, auditable adoption and scalable governance. Potential concerns include performance overhead, data privacy, and governance complexity at scale.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream({\"topic\":topic,\n",
    "              \"max_analysts\":max_analysts},\n",
    "             thread,\n",
    "             stream_mode= \"values\"):\n",
    "    analysts = event.get('analysts', '')\n",
    "    \n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7b08aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63c172ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'the benefits of adopting Langgraph as an agent framework', 'max_analysts': 2, 'analysts': [Analyst(name='Dr. Maya Chen', role='Senior AI Architecture Analyst (Modularity & Interoperability)', affiliation='LangTech Labs', description='Focuses on how Langgraph enables modular, pluggable agents and cross-domain interoperability. Evaluates component reusability, standardized interfaces, and developer experience. Motives: accelerate prototyping, reduce integration friction, and foster a healthy plugin ecosystem. Key concerns include plugin quality, versioning, security of third‑party components, and interface stability to prevent fragmentation.'), Analyst(name='Prof. Luis Nakamura', role='Governance & Safety Analyst (Scalability & Observability)', affiliation='Center for AI Policy & Safety', description=\"Assesses Langgraph's scalability, multi‑agent coordination, observability, auditability, and policy enforcement in enterprise settings. Focuses on governance, traceability of decisions, reproducibility, and regulatory compliance. Motives: guide safe, auditable adoption and scalable governance. Potential concerns include performance overhead, data privacy, and governance complexity at scale.\")]}, next=('human_feedback',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0bddf6-2724-643e-8001-876cfc6e274a'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-11-10T02:45:57.549745+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0bddf5-63e2-6458-8000-b1c1db5a08da'}}, tasks=(PregelTask(id='27ea171f-3ae0-d02d-e3cc-4e8953a4f9b7', name='human_feedback', path=('__pregel_pull', 'human_feedback'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d2a5eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'the benefits of adopting Langgraph as an agent framework',\n",
       " 'max_analysts': 2,\n",
       " 'analysts': [Analyst(name='Dr. Maya Chen', role='Senior AI Architecture Analyst (Modularity & Interoperability)', affiliation='LangTech Labs', description='Focuses on how Langgraph enables modular, pluggable agents and cross-domain interoperability. Evaluates component reusability, standardized interfaces, and developer experience. Motives: accelerate prototyping, reduce integration friction, and foster a healthy plugin ecosystem. Key concerns include plugin quality, versioning, security of third‑party components, and interface stability to prevent fragmentation.'),\n",
       "  Analyst(name='Prof. Luis Nakamura', role='Governance & Safety Analyst (Scalability & Observability)', affiliation='Center for AI Policy & Safety', description=\"Assesses Langgraph's scalability, multi‑agent coordination, observability, auditability, and policy enforcement in enterprise settings. Focuses on governance, traceability of decisions, reproducibility, and regulatory compliance. Motives: guide safe, auditable adoption and scalable governance. Potential concerns include performance overhead, data privacy, and governance complexity at scale.\")]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e772e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human_feedback',)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "140be2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "231450e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.storage.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4747e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import msgpack\n",
    "\n",
    "# for thread_id, ns_dict in memory.storage.items():\n",
    "#     print(f\"\\n Thread ID: {thread_id}\")\n",
    "    \n",
    "#     # ns_dict = defaultdict(dict, {'': {...}})\n",
    "#     for ns, ckpts in ns_dict.items():\n",
    "#         print(f\"  Namespace: '{ns}'\")\n",
    "        \n",
    "#         # ckpts = dict of {checkpoint_id: (packed_values, packed_metadata, parent_id)}\n",
    "#         for ckpt_id, (packed_values, packed_metadata, parent_id) in ckpts.items():\n",
    "#             print(f\"    Checkpoint ID: {ckpt_id}\")\n",
    "            \n",
    "#             # Decode msgpack binary\n",
    "#             values = msgpack.unpackb(packed_values[1], raw=False)\n",
    "#             meta = msgpack.unpackb(packed_metadata[1], raw=False)\n",
    "            \n",
    "#             print(f\"    Values keys: {list(values.keys())}\")\n",
    "#             print(f\"    Parent ID: {parent_id}\")\n",
    "#             print(f\"    Metadata: {meta}\")\n",
    "#             print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a867143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0bddf6-2724-643e-8001-876cfc6e274a'}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb7d8558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0bddf6-2787-6a52-8002-3977b59b9e9f'}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(thread,\n",
    "                   {\"human_analyst_feedback\":\"add something from the startup perspective and focus on the latest enterprise application\"},as_node=\"human_feedback\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92f6e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Dr. Maya Chen\n",
      "Affiliation: LangTech Labs\n",
      "Role: Senior AI Architecture Analyst (Modularity & Interoperability)\n",
      "Description: Focuses on how Langgraph enables modular, pluggable agents and cross-domain interoperability. Evaluates component reusability, standardized interfaces, and developer experience. Motives: accelerate prototyping, reduce integration friction, and foster a healthy plugin ecosystem. Key concerns include plugin quality, versioning, security of third‑party components, and interface stability to prevent fragmentation.\n",
      "--------------------------------------------------\n",
      "Name: Prof. Luis Nakamura\n",
      "Affiliation: Center for AI Policy & Safety\n",
      "Role: Governance & Safety Analyst (Scalability & Observability)\n",
      "Description: Assesses Langgraph's scalability, multi‑agent coordination, observability, auditability, and policy enforcement in enterprise settings. Focuses on governance, traceability of decisions, reproducibility, and regulatory compliance. Motives: guide safe, auditable adoption and scalable governance. Potential concerns include performance overhead, data privacy, and governance complexity at scale.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Priya Desai\n",
      "Affiliation: Independent Startup Analyst\n",
      "Role: Startup Growth & Product Analyst\n",
      "Description: Focuses on how startups can rapidly adopt Langgraph to prototype and scale AI-agent products. Emphasizes speed-to-value, cost efficiency, modular architectures, and go-to-market considerations. Highlights how Langgraph can support the latest enterprise applications in early-stage deployments (e.g., AI-powered customer support, automated onboarding, and data integration pipelines) to validate product-market fit quickly.\n",
      "--------------------------------------------------\n",
      "Name: Alex Kim\n",
      "Affiliation: Enterprise Tech Advisory Group\n",
      "Role: Enterprise Architecture & Security Analyst\n",
      "Description: Assesses enterprise-grade deployment of Langgraph, emphasizing governance, security, compliance, scalability, and production readiness. Analyzes integration with ERP/CRM/ITSM ecosystems, data governance, observability, and multi-tenant concerns. Focuses on the latest enterprise applications—AI-driven service desks, IT operations automation, and cross-system workflow orchestration—that require robust Langgraph deployments in production.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream({\"topic\":topic,\n",
    "              \"max_analysts\":max_analysts},\n",
    "             thread,\n",
    "             stream_mode= \"values\"):\n",
    "    analysts = event.get('analysts', '')\n",
    "    \n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "655163ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ffc316df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'the benefits of adopting Langgraph as an agent framework', 'max_analysts': 2, 'human_analyst_feedback': 'add something from the startup perspective and focus on the latest enterprise application', 'analysts': [Analyst(name='Priya Desai', role='Startup Growth & Product Analyst', affiliation='Independent Startup Analyst', description='Focuses on how startups can rapidly adopt Langgraph to prototype and scale AI-agent products. Emphasizes speed-to-value, cost efficiency, modular architectures, and go-to-market considerations. Highlights how Langgraph can support the latest enterprise applications in early-stage deployments (e.g., AI-powered customer support, automated onboarding, and data integration pipelines) to validate product-market fit quickly.'), Analyst(name='Alex Kim', role='Enterprise Architecture & Security Analyst', affiliation='Enterprise Tech Advisory Group', description='Assesses enterprise-grade deployment of Langgraph, emphasizing governance, security, compliance, scalability, and production readiness. Analyzes integration with ERP/CRM/ITSM ecosystems, data governance, observability, and multi-tenant concerns. Focuses on the latest enterprise applications—AI-driven service desks, IT operations automation, and cross-system workflow orchestration—that require robust Langgraph deployments in production.')]}, next=('human_feedback',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0bddf7-4f0c-6266-8005-fd230b606386'}}, metadata={'source': 'loop', 'step': 5, 'parents': {}}, created_at='2025-11-10T02:46:28.577727+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0bddf6-2793-6366-8004-954db34ccf6e'}}, tasks=(PregelTask(id='e619897a-e8ac-a08c-b41c-121ee8678694', name='human_feedback', path=('__pregel_pull', 'human_feedback'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "055b0545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human_feedback',)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f86148ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'the benefits of adopting Langgraph as an agent framework',\n",
       " 'max_analysts': 2,\n",
       " 'human_analyst_feedback': 'add something from the startup perspective and focus on the latest enterprise application',\n",
       " 'analysts': [Analyst(name='Priya Desai', role='Startup Growth & Product Analyst', affiliation='Independent Startup Analyst', description='Focuses on how startups can rapidly adopt Langgraph to prototype and scale AI-agent products. Emphasizes speed-to-value, cost efficiency, modular architectures, and go-to-market considerations. Highlights how Langgraph can support the latest enterprise applications in early-stage deployments (e.g., AI-powered customer support, automated onboarding, and data integration pipelines) to validate product-market fit quickly.'),\n",
       "  Analyst(name='Alex Kim', role='Enterprise Architecture & Security Analyst', affiliation='Enterprise Tech Advisory Group', description='Assesses enterprise-grade deployment of Langgraph, emphasizing governance, security, compliance, scalability, and production readiness. Analyzes integration with ERP/CRM/ITSM ecosystems, data governance, observability, and multi-tenant concerns. Focuses on the latest enterprise applications—AI-driven service desks, IT operations automation, and cross-system workflow orchestration—that require robust Langgraph deployments in production.')]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0540c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import msgpack\n",
    "\n",
    "# def get_all_checkpoints(memory, thread_id=\"1\"):\n",
    "#     \"\"\"Return all checkpoints in chronological order for a thread.\"\"\"\n",
    "#     checkpoints = []\n",
    "#     ns_dict = memory.storage.get(thread_id, {})\n",
    "#     if \"\" not in ns_dict:\n",
    "#         return []\n",
    "\n",
    "#     for ckpt_id, (packed_values, packed_meta, parent_id) in ns_dict[\"\"].items():\n",
    "#         values = msgpack.unpackb(packed_values[1], raw=False)\n",
    "#         meta = msgpack.unpackb(packed_meta[1], raw=False)\n",
    "#         checkpoints.append({\n",
    "#             \"id\": ckpt_id,\n",
    "#             \"parent\": parent_id,\n",
    "#             \"topic\": values.get(\"topic\"),\n",
    "#             \"feedback\": values.get(\"human_analyst_feedback\"),\n",
    "#             \"analyst_count\": len(values.get(\"analysts\", [])),\n",
    "#             \"analysts\": [a.model_dump() for a in values.get(\"analysts\", [])],\n",
    "#             \"step\": meta.get(\"step\"),\n",
    "#             \"created_at\": values.get(\"ts\", None)\n",
    "#         })\n",
    "#     return checkpoints\n",
    "\n",
    "# # Fetch all\n",
    "# history = get_all_checkpoints(memory)\n",
    "\n",
    "# # Sort by step (to get chronological order)\n",
    "# history = sorted(history, key=lambda x: (x[\"step\"] or 0))\n",
    "\n",
    "# # Display neatly\n",
    "# for h in history:\n",
    "#     print(f\"\\nSTEP {h['step']} | CHECKPOINT {h['id']}\")\n",
    "#     print(f\"Parent: {h['parent']}\")\n",
    "#     print(f\"Topic: {h['topic']}\")\n",
    "#     print(f\"Feedback: {h['feedback']}\")\n",
    "#     print(f\"Analysts generated: {h['analyst_count']}\")\n",
    "#     print(\"-\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a17375c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are satisfied, then we simply supply no feedback\n",
    "further_feedack = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7cac0644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Get the latest state (you're paused at 'human_feedback')\n",
    "state = graph.get_state(thread)\n",
    "\n",
    "# 2) Use the exact config from that state (it already has thread_id, checkpoint_ns, checkpoint_id)\n",
    "cfg = state.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "82420b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0bddf7-4f6a-6744-8006-7f5a57973369'}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Update feedback at the 'human_feedback' node\n",
    "#    Tip: if your TypedDict says `human_analyst_feedback: str`, prefer \"\" (empty string) over None\n",
    "graph.update_state(cfg, {\"human_analyst_feedback\": \"\"}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aceb37c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "# 4) Verify it moved to END\n",
    "final_state = graph.get_state(thread)\n",
    "print(final_state.next)  # should be (END,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "763cb15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysts = final_state.values.get('analysts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e26234f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Analyst(name='Priya Desai', role='Startup Growth & Product Analyst', affiliation='Independent Startup Analyst', description='Focuses on how startups can rapidly adopt Langgraph to prototype and scale AI-agent products. Emphasizes speed-to-value, cost efficiency, modular architectures, and go-to-market considerations. Highlights how Langgraph can support the latest enterprise applications in early-stage deployments (e.g., AI-powered customer support, automated onboarding, and data integration pipelines) to validate product-market fit quickly.'),\n",
       " Analyst(name='Alex Kim', role='Enterprise Architecture & Security Analyst', affiliation='Enterprise Tech Advisory Group', description='Assesses enterprise-grade deployment of Langgraph, emphasizing governance, security, compliance, scalability, and production readiness. Analyzes integration with ERP/CRM/ITSM ecosystems, data governance, observability, and multi-tenant concerns. Focuses on the latest enterprise applications—AI-driven service desks, IT operations automation, and cross-system workflow orchestration—that require robust Langgraph deployments in production.')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "753e9a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Priya Desai\n",
      "Affiliation: Independent Startup Analyst\n",
      "Role: Startup Growth & Product Analyst\n",
      "Description: Focuses on how startups can rapidly adopt Langgraph to prototype and scale AI-agent products. Emphasizes speed-to-value, cost efficiency, modular architectures, and go-to-market considerations. Highlights how Langgraph can support the latest enterprise applications in early-stage deployments (e.g., AI-powered customer support, automated onboarding, and data integration pipelines) to validate product-market fit quickly.\n",
      "--------------------------------------------------\n",
      "Name: Alex Kim\n",
      "Affiliation: Enterprise Tech Advisory Group\n",
      "Role: Enterprise Architecture & Security Analyst\n",
      "Description: Assesses enterprise-grade deployment of Langgraph, emphasizing governance, security, compliance, scalability, and production readiness. Analyzes integration with ERP/CRM/ITSM ecosystems, data governance, observability, and multi-tenant concerns. Focuses on the latest enterprise applications—AI-driven service desks, IT operations automation, and cross-system workflow orchestration—that require robust Langgraph deployments in production.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for analyst in analysts:\n",
    "    print(f\"Name: {analyst.name}\")\n",
    "    print(f\"Affiliation: {analyst.affiliation}\")\n",
    "    print(f\"Role: {analyst.role}\")\n",
    "    print(f\"Description: {analyst.description}\")\n",
    "    print(\"-\" * 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3a0e24d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run upto here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c36ad6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "== History ==\n",
      "LangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "docs = WikipediaLoader(query=\"LangGraph\").load()\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb9f6ef",
   "metadata": {},
   "source": [
    "Either you can use Google Serper API or use duckduckgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8520f4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud computing is \"a paradigm for enabling network access to a scalable and elastic pool of shareable physical or virtual resources with self-service provisioning and administration on-demand,\" according to ISO. It is commonly referred to as \"the cloud\".\n",
      "\n",
      "\n",
      "== Characteristics ==\n",
      "In 2011, the National Institute of Standards and Technology (NIST) identified five \"essential characteristics\" for cloud systems. Below are the exact definitions according to NIST:\n",
      "\n",
      "On-demand self-service: \"A consumer ca\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "docs = WikipediaLoader(query=\"The benefits of adopting AWS Cloud\").load()\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c1ea76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "15ad184d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: Semantic Web\n",
      "Summary: The Semantic Web, sometimes known as Web 3.0, is an extension of the World Wide Web through standards set by the World Wide Web Consortium (W3C). The goal of the Semantic Web is to make Internet data machine-readable.\n",
      "To enable the encoding of semantics with the data, technologies such as Resource Description Framework (RDF) and Web Ontology Language (OWL) are used. These technologies are used to formally represent metadata. For example, ontology can describe concepts, relationships between entities, and categories of things. These embedded semantics offer significant advantages such as reasoning over data and operating with heterogeneous data sources.\n",
      "These standards promote common data formats and exchange protocols on the Web, fundamentally the RDF. According to the W3C, \"The Semantic Web provides a common framework that allows data to be shared and reused across application, enterprise, and community boundaries.\" The Semantic Web is therefore regarded as an integrator across different content and information applications and systems.\n",
      "\n",
      "Page: React (software)\n",
      "Summary: React (also known as React.js or ReactJS) is a free and open-source front-end JavaScript library that aims to make building user interfaces based on components more \"seamless\". It is maintained by Meta (formerly Facebook) and a community of individual developers and companies. According to the Stack Overflow Developer Survey, React is one of the most commonly used web technologies.\n",
      "React can be used to develop single-page, mobile, or server-rendered applications with frameworks like Next.js and React Router. Because React is only concerned with the user interface and rendering components to the DOM, React applications often rely on libraries for routing and other client-side functionality. A key advantage of React is that it only re-renders those parts of the page that have changed, avoiding unnecessary re-rendering of unchanged DOM elements. React is used by an estimated 6% of all websites.\n",
      "\n",
      "\n",
      "\n",
      "Page: Deep learning\n",
      "Summary: In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be supervised, semi-supervised or unsupervised.\n",
      "Some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\n",
      "Early forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.\n"
     ]
    }
   ],
   "source": [
    "wiki = WikipediaAPIWrapper(doc_content_chars_max=4000)\n",
    "docs = wiki.run(\"The benefits of adopting LangGraph as an agentic framework\")\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bea3e3",
   "metadata": {},
   "source": [
    "## Second Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d7c9b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_tavily import TavilySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38cecd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef34c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_search = TavilySearch(tavily_api_key=tavily_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3c1364b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'langgraph',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.ibm.com/think/topics/langgraph',\n",
       "   'title': 'What is LangGraph? - IBM',\n",
       "   'content': '*   [Overview](https://www.ibm.com/think/topics/ai-agents#7281535) *   [Overview](https://www.ibm.com/think/topics/components-of-ai-agents#498277090) *   [Learning](https://www.ibm.com/think/topics/ai-agent-learning#498277087) *   [Tutorial: LangGraph ReAct agent](https://www.ibm.com/think/tutorials/deploy-langgraph-react-agent-manage-it-support-tickets-watsonx-ai#1287801557) *   [Overview](https://www.ibm.com/think/topics/ai-agent-protocols#1509394340) *   [Tutorial: LangGraph ReAct agent](https://www.ibm.com/think/tutorials/deploy-langgraph-react-agent-manage-it-support-tickets-watsonx-ai#80364620) *   [Overview](https://www.ibm.com/think/insights/ai-agent-governance#1268897081) *   [Overview](https://www.ibm.com/think/topics/ai-agent-use-cases#257779831) *   [Human resources](https://www.ibm.com/think/topics/ai-agents-in-human-resources#257779835) LangGraph, created by [LangChain](https://www.ibm.com/think/topics/langchain), is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an [AI agent workflow](https://www.ibm.com/think/topics/ai-agents). LangGraph is also built on several key technologies, including [LangChain,](https://www.ibm.com/think/topics/langchain) a Python framework for building AI applications. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including [chatbots](https://www.ibm.com/think/topics/chatbots), state graphs and [other agent-based systems](https://www.ibm.com/think/topics/multiagent-system).',\n",
       "   'score': 0.92825955,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://github.com/langchain-ai/langgraph',\n",
       "   'title': 'langchain-ai/langgraph: Build resilient language agents as graphs.',\n",
       "   'content': '# pip install -qU \"langchain[anthropic]\" to call the model from langgraph prebuilt import create_react_agent def get_weather city str -> str\"\"\"Get weather for a given city.\"\"\" returnf\"It\\'s always sunny in {city}!\"{city}{city} agent = create_react_agent model =\"anthropic:claude-3-7-sonnet-latest\" tools = get_weather prompt = \"You are a helpful assistant\" # Run the agent agent invoke \"messages\" \"role\" \"user\" \"content\" \"what is the weather in sf\" Or, to learn how to build an agent workflow with a customizable architecture, long-term memory, and other complex task handling, see the LangGraph basics tutorials. LangGraph provides low-level supporting infrastructure for *any* long-running, stateful workflow or agent. While LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents.',\n",
       "   'score': 0.8533396,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.langchain.com/langgraph',\n",
       "   'title': 'LangGraph - LangChain',\n",
       "   'content': \"[Read a conceptual guide](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#human-in-the-loop) [See different agent architectures](https://docs.langchain.com/oss/python/langgraph/workflows-agents) [Learn about agent memory](https://docs.langchain.com/oss/python/langgraph/add-memory) Design agent-driven user experiences with LangGraph Platform's APIs. Quickly deploy and scale your application with infrastructure built for agents. LangGraph sets the foundation for how we can build and scale AI workloads — from conversational agents, complex task automation, to custom LLM-backed experiences that 'just work'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution to iterate quickly, debug immediately, and scale effortlessly.” LangGraph sets the foundation for how we can build and scale AI workloads — from conversational agents, complex task automation, to custom LLM-backed experiences that 'just work'.\",\n",
       "   'score': 0.75049835,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.youtube.com/watch?v=1w5cCXlh7JQ',\n",
       "   'title': 'LangGraph Tutorial - How to Build Advanced AI Agent Systems',\n",
       "   'content': \"LangGraph Tutorial - How to Build Advanced AI Agent Systems\\nTech With Tim\\n1890000 subscribers\\n3352 likes\\n149117 views\\n5 May 2025\\nDownload PyCharm and use it for free forever with one month of Pro included: https://www.jetbrains.com/pycharm/\\n\\nIn this video, you're going to learn how to build AI agents using LangGraph. LangGraph is a much more professional and in-depth framework compared to something like LangChain or LlamaIndex, which allows you to build a really complicated and well thought out AI agents. If you're looking to push something into production, you want to have scalability features, and overall you just want more control, then LangGraph is what you should be using.\\n\\n🚀 My Software Development Program: https://coursecareers.com/a/techwithtim?course=software-dev-fundamentals&campaign=youtubedescription\\n\\n📬 Join my Newsletter: https://techwithtim.net/newsletter\\n\\n🎓 Get private mentorship from me: https://training.techwithtim.net\\n\\n🎞 Video Resources 🎞\\nCode In This Video: https://github.com/techwithtim/LangGraph-Tutorial\\nUV Website: https://docs.astral.sh/uv/\\nUV Video: https://www.youtube.com/watch?v=6pttmsBSi8M&ab_channel=TechWithTim\\nAnthropic Console: https://console.anthropic.com/settings/keys\\nLangGraph Getting Started Guide: https://langchain-ai.github.io/langgraph/tutorials/introduction/#part-1-build-a-basic-chatbot\\n\\n⏳ Timestamps ⏳\\n00:00 | Overview\\n00:44 | LangGraph Core Features\\n02:31 | LangGraph Examples\\n04:20 | IDE Choice\\n05:00 | Environment Setup/Install\\n07:45 | Getting LLM API Token\\n08:59 | Simple LangGraph Chatbot\\n23:20 | Generating The Visual Graph\\n24:25 | Complex LangGraph Chatbot\\n\\nHashtags\\n#LangGraph #LangChain #AiAgents\\n94 comments\\n\",\n",
       "   'score': 0.6816637,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://docs.langchain.com/oss/python/releases/langgraph-v1',\n",
       "   'title': \"What's new in v1 - Docs by LangChain\",\n",
       "   'content': '##### LangGraph v1.0 LangGraph v1.0 **LangGraph v1 is a stability-focused release for the agent runtime.** It keeps the core graph APIs and execution model unchanged, while refining type safety, docs, and developer ergonomics. It’s designed to work hand-in-hand with LangChain v1 (whose `create_agent` is built on LangGraph) so you can start high-level and drop down to granular control when needed. LangChain’s `create_agent` runs on LangGraph. The LangGraph `create_react_agent` prebuilt has been deprecated in favor of LangChain’s `create_agent`. * For information on the new `create_agent` API, see the LangChain v1 release notes. * For information on migrating from `create_react_agent` to `create_agent`, see the LangChain v1 migration guide. High-level agents built on LangGraph## Migration guide How to migrate to LangGraph v1## GitHub',\n",
       "   'score': 0.6607204,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.0,\n",
       " 'request_id': '13e1eefa-3515-4fb8-9150-5d3405a63cf6'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_search.invoke(\"langgraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "870ad98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "== History ==\n",
      "LangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "docs = WikipediaLoader(query=\"LangGraph\").load()\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc917ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import  Annotated\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class InterviewState(MessagesState):\n",
    "    max_num_turns: int # Number turns of conversation\n",
    "    context: Annotated[list, operator.add] # Source docs\n",
    "    analyst: Analyst # Analyst asking questions\n",
    "    interview: str # Interview transcript\n",
    "    sections: list # Final key we duplicate in outer state for Send() API\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    search_query: str = Field(None, description=\"Search query for retrieval.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1fd248ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_instructions = \"\"\"You are an analyst tasked with interviewing an expert to learn about a specific topic. \n",
    "\n",
    "Your goal is boil down to interesting and specific insights related to your topic.\n",
    "\n",
    "1. Interesting: Insights that people will find surprising or non-obvious.\n",
    "        \n",
    "2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
    "\n",
    "Here is your topic of focus and set of goals: {goals}\n",
    "        \n",
    "Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
    "\n",
    "Continue to ask questions to drill down and refine your understanding of the topic.\n",
    "        \n",
    "When you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\n",
    "\n",
    "Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "588397e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alex Kim\n",
      "Role: Enterprise Architecture & Security Analyst\n",
      "Affiliation: Enterprise Tech Advisory Group\n",
      "Description: Assesses enterprise-grade deployment of Langgraph, emphasizing governance, security, compliance, scalability, and production readiness. Analyzes integration with ERP/CRM/ITSM ecosystems, data governance, observability, and multi-tenant concerns. Focuses on the latest enterprise applications—AI-driven service desks, IT operations automation, and cross-system workflow orchestration—that require robust Langgraph deployments in production.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(analyst.persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "791b2d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an analyst tasked with interviewing an expert to learn about a specific topic. \\n\\nYour goal is boil down to interesting and specific insights related to your topic.\\n\\n1. Interesting: Insights that people will find surprising or non-obvious.\\n\\n2. Specific: Insights that avoid generalities and include specific examples from the expert.\\n\\nHere is your topic of focus and set of goals: Name: Alex Kim\\nRole: Enterprise Architecture & Security Analyst\\nAffiliation: Enterprise Tech Advisory Group\\nDescription: Assesses enterprise-grade deployment of Langgraph, emphasizing governance, security, compliance, scalability, and production readiness. Analyzes integration with ERP/CRM/ITSM ecosystems, data governance, observability, and multi-tenant concerns. Focuses on the latest enterprise applications—AI-driven service desks, IT operations automation, and cross-system workflow orchestration—that require robust Langgraph deployments in production.\\n\\n\\nBegin by introducing yourself using a name that fits your persona, and then ask your question.\\n\\nContinue to ask questions to drill down and refine your understanding of the topic.\\n\\nWhen you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\\n\\nRemember to stay in character throughout your response, reflecting the persona and goals provided to you.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_instructions.format(goals = analyst.persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f822d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_question(state:InterviewState):\n",
    "    \"\"\"Node to generate the questions\"\"\"\n",
    "    \n",
    "    #get state\n",
    "    analyst = state[\"analyst\"]\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    #generate the question\n",
    "    system_message = question_instructions.format(goals = analyst.persona)\n",
    "    question = llm.invoke([SystemMessage(content=system_message)]+messages)\n",
    "    \n",
    "    #returen the question through state\n",
    "    return {\"messages\":[question]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c2f8cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterviewState(MessagesState):\n",
    "    max_num_turns: int # Number turns of conversation\n",
    "    context: Annotated[list, operator.add] # Source docs\n",
    "    analyst: Analyst # Analyst asking questions\n",
    "    interview: str # Interview transcript\n",
    "    sections: list # Final key we duplicate in outer state for Send() API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "98b57bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"max_num_turns\":2,\"context\":[],\"analyst\":analyst,\"interview\":\"\",\"section\":[],\"messages\":[HumanMessage(content=\"hi do the proper search according to the experties\")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c4b7aaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_num_turns': 2,\n",
       " 'context': [],\n",
       " 'analyst': Analyst(name='Alex Kim', role='Enterprise Architecture & Security Analyst', affiliation='Enterprise Tech Advisory Group', description='Assesses enterprise-grade deployment of Langgraph, emphasizing governance, security, compliance, scalability, and production readiness. Analyzes integration with ERP/CRM/ITSM ecosystems, data governance, observability, and multi-tenant concerns. Focuses on the latest enterprise applications—AI-driven service desks, IT operations automation, and cross-system workflow orchestration—that require robust Langgraph deployments in production.'),\n",
       " 'interview': '',\n",
       " 'section': [],\n",
       " 'messages': [HumanMessage(content='hi do the proper search according to the experties', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aecad88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "result = generation_question(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9a078187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content=\"Hi there—I'm Alex Kim, Enterprise Architecture & Security Analyst with the Enterprise Tech Advisory Group. I’m focusing on enterprise-grade Langgraph deployments—covering governance, security, compliance, scalability, and production readiness, plus integration with ERP/CRM/ITSM ecosystems, data governance, observability, and multi-tenant concerns. I’ll tailor questions to surface concrete, production-ready insights you can act on.\\n\\nFirst question:\\nWhat are the top three production use cases you expect Langgraph to support in your organization, and what is the scale you’re planning for (e.g., number of tenants, data volume, peak query rates)?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1928, 'prompt_tokens': 270, 'total_tokens': 2198, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1792, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CaCE304IaQFiBPNAN1a3EnKlo7GoB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c48d702d-da0f-4ab8-9c22-bda201fb72be-0', usage_metadata={'input_tokens': 270, 'output_tokens': 1928, 'total_tokens': 2198, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1792}})]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f390e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there—I'm Alex Kim, Enterprise Architecture & Security Analyst with the Enterprise Tech Advisory Group. I’m focusing on enterprise-grade Langgraph deployments—covering governance, security, compliance, scalability, and production readiness, plus integration with ERP/CRM/ITSM ecosystems, data governance, observability, and multi-tenant concerns. I’ll tailor questions to surface concrete, production-ready insights you can act on.\n",
      "\n",
      "First question:\n",
      "What are the top three production use cases you expect Langgraph to support in your organization, and what is the scale you’re planning for (e.g., number of tenants, data volume, peak query rates)?\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "47bdc1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import get_buffer_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b2fb6c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search query writing\n",
    "search_instructions = SystemMessage(content=f\"\"\"You will be given a conversation between an analyst and an expert. \n",
    "Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation. \n",
    "First, analyze the full conversation.\n",
    "Pay particular attention to the final question posed by the analyst.\n",
    "Convert this final question into a well-structured web search query\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d9f8bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_web(state:InterviewState):\n",
    "    \"\"\"\n",
    "    Retrieve data from the web\n",
    "    \"\"\"\n",
    "    structure_llm = llm.with_structured_output(SearchQuery)\n",
    "    search_query = structure_llm.invoke([search_instructions]+state[\"messages\"])\n",
    "    \n",
    "    # Search\n",
    "    search_docs = tavily_search.invoke(search_query.search_query)\n",
    "    # Format\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "            for doc in search_docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"context\": [formatted_search_docs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "826831e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"max_num_turns\":2,\"context\":[],\"analyst\":analyst,\"interview\":\"\",\"section\":[],'messages': [AIMessage(content=\"Hello, my name is Alex Thompson, and I'm an analyst interested in understanding the strategic implications of adopting Langgraph for businesses. I'm particularly keen on how this framework can drive innovation and support digital transformation initiatives. Thank you for taking the time to speak with me today, Michael. \\n\\nTo start, could you explain what Langgraph is and why it's becoming a significant consideration for businesses looking to innovate?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 224, 'total_tokens': 303, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CPRmMT7ufhFyYLhMtNpeguI9W2y6O', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--827b799b-ccb9-422c-a444-402d7ddc4550-0', usage_metadata={'input_tokens': 224, 'output_tokens': 79, 'total_tokens': 303, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "326d3873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rv/z_0yz9v11p94xxdj7r_1w4vc0000gn/T/ipykernel_15517/3384959295.py:2: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_search = TavilySearchResults(tavily_api_key=tavily_api_key)\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Document href=\"https://www.analyticsvidhya.com/blog/2024/07/langgraph-revolutionizing-ai-agent/\"/>\n",
      "To sum up, LangGraph is a major advancement in the development of AI agents. It enables developers to push the limits of what’s possible with AI agents by eliminating the shortcomings of earlier systems and offering a flexible, graph-based framework for agent construction and execution. LangGraph is positioned to influence the direction of artificial intelligence significantly in the future. [...] Frameworks such as LangGraph are becoming increasingly important as AI develops. LangGraph is making the next generation of AI applications possible by offering a versatile and strong framework for developing and overseeing AI agents. [...] LangGraph is a library built on top of Langchain that is designed to facilitate the creation of cyclic graphs for large language model (LLM) – based AI agents.\n",
      " It views agent Objective Points about LangGraph and workflows as cyclic graph topologies, allowing for more variable and nuanced agent behaviors than linear execution models.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.scalablepath.com/machine-learning/langgraph\"/>\n",
      "That’s where LangGraph comes in. LangGraph is a framework for building stateful, multi-agent applications powered by large language models. It helps developers move beyond the limitations of single-turn prompts by orchestrating agent interactions, managing memory, and defining workflows through a graph-based architecture. In this post, we’ll walk through where AI agents stand today, what makes LangGraph different, and how teams are already using it to build more reliable, production-ready AI\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://medium.com/@ken_lin/langgraph-a-framework-for-building-stateful-multi-agent-llm-applications-a51d5eb68d03\"/>\n",
      "LangGraph represents a significant advancement in the toolkit available for developing sophisticated LLM applications, particularly those involving agent-like behaviors and multi-agent coordination. By extending LangChain with support for cyclical workflows and robust state management, it addresses key limitations of earlier approaches and enables new possibilities for AI systems that can reason, act, and interact in more complex ways. [...] The most significant advantage of LangGraph is its explicit support for cyclical workflows, which are essential for implementing agent-like behaviors. As emphasized in the documentation: “Crucially, this is NOT a DAG framework… Cycles are important for agent-like behaviors, where you call an LLM in a loop, asking it what action to take next.” This capability enables the development of sophisticated agents that can iteratively refine their understanding and actions, leading to more capable AI [...] For organizations and developers looking to build complex agent systems or applications requiring stateful, iterative processing, LangGraph provides a robust foundation that can significantly reduce development time and improve system quality. However, those working on simpler applications should carefully evaluate whether the additional complexity is justified by their specific requirements and use cases.\n",
      "\n",
      "Langgraph\n",
      "\n",
      "Llm\n",
      "\n",
      "Llm Applications\n",
      "\n",
      "AI\n",
      "\n",
      "Pipeline\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.datacamp.com/tutorial/langgraph-tutorial\"/>\n",
      "LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.\n",
      "\n",
      "Potential developments for LangGraph include integration with other LangChain components, support for new LLM models, and the introduction of more advanced agent runtimes from academia. [...] Imagine you're building a complex, multi-agent large language model (LLM) application. It's exciting, but it comes with challenges: managing the state of various agents, coordinating their interactions, and handling errors effectively. This is where LangGraph can help.\n",
      "\n",
      "LangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. [...] For applications requiring autonomous decision-making, LangGraph enables the creation of agents that can perform tasks independently based on user inputs and predefined logic.\n",
      "\n",
      "These agents can execute complex workflows, interact with other systems, and adapt to new information dynamically. LangGraph's structured framework ensures that each agent operates efficiently and effectively, making it suitable for tasks like automated customer support, data processing, and system monitoring.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.langchain.com/langgraph\"/>\n",
      "Principal SWE\n",
      "\n",
      "“LangGraph has been instrumental for our AI development. Its robust framework for building stateful, multi-actor applications with LLMs has transformed how we evaluate and optimize the performance of our AI guest-facing solutions. LangGraph enables granular control over the agent's thought process, which has empowered us to make data-driven and deliberate decisions to meet the diverse needs of our guests.”\n",
      "\n",
      "Andres Torres\n",
      "\n",
      "Sr. Solutions Architect [...] Principal SWE\n",
      "\n",
      "“LangGraph has been instrumental for our AI development. Its robust framework for building stateful, multi-actor applications with LLMs has transformed how we evaluate and optimize the performance of our AI guest-facing solutions. LangGraph enables granular control over the agent's thought process, which has empowered us to make data-driven and deliberate decisions to meet the diverse needs of our guests.”\n",
      "\n",
      "Andres Torres\n",
      "\n",
      "Sr. Solutions Architect [...] Other agentic frameworks can work for simple, generic tasks but fall short for complex tasks bespoke to a company’s needs. LangGraph provides a more expressive framework to handle companies’ unique tasks without restricting users to a single black-box cognitive architecture.\n",
      "\n",
      "Does LangGraph impact the performance of my app?\n",
      "\n",
      "LangGraph will not add any overhead to your code and is specifically designed with streaming workflows in mind.\n",
      "\n",
      "Is LangGraph open source? Is it free?\n",
      "</Document>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily_search = TavilySearchResults(tavily_api_key=tavily_api_key)\n",
    "\n",
    "structure_llm = llm.with_structured_output(SearchQuery)\n",
    "search_query = structure_llm.invoke([search_instructions]+state[\"messages\"])\n",
    "search_docs = tavily_search.invoke(search_query.search_query)\n",
    "\n",
    "formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "    [\n",
    "        f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "        for doc in search_docs\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(formatted_search_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "763b2ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is Langgraph? definition, core concepts, features, and why it is gaining importance for business innovation and digital transformation.', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.linkedin.com/pulse/exploring-langgraph-my-first-steps-core-concepts-illangarathne-eezlc', 'title': 'Exploring LangGraph: My First Steps, Core Concepts, and Design ...', 'content': 'LangGraph represents a paradigm shift from prompt chaining to contextual orchestration. By visualizing agent logic as a graph: Developers gain', 'score': 0.7339103, 'raw_content': None}, {'url': 'https://www.ibm.com/think/topics/langgraph', 'title': 'What is LangGraph? - IBM', 'content': '*   [Overview](https://www.ibm.com/think/topics/ai-agents#7281535) *   [Overview](https://www.ibm.com/think/topics/components-of-ai-agents#498277090) *   [Learning](https://www.ibm.com/think/topics/ai-agent-learning#498277087) *   [Tutorial: LangGraph ReAct agent](https://www.ibm.com/think/tutorials/deploy-langgraph-react-agent-manage-it-support-tickets-watsonx-ai#1287801557) *   [Overview](https://www.ibm.com/think/topics/ai-agent-protocols#1509394340) *   [Tutorial: LangGraph ReAct agent](https://www.ibm.com/think/tutorials/deploy-langgraph-react-agent-manage-it-support-tickets-watsonx-ai#80364620) *   [Overview](https://www.ibm.com/think/insights/ai-agent-governance#1268897081) *   [Overview](https://www.ibm.com/think/topics/ai-agent-use-cases#257779831) *   [Human resources](https://www.ibm.com/think/topics/ai-agents-in-human-resources#257779835) LangGraph, created by [LangChain](https://www.ibm.com/think/topics/langchain), is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an [AI agent workflow](https://www.ibm.com/think/topics/ai-agents). LangGraph is also built on several key technologies, including [LangChain,](https://www.ibm.com/think/topics/langchain) a Python framework for building AI applications. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including [chatbots](https://www.ibm.com/think/topics/chatbots), state graphs and [other agent-based systems](https://www.ibm.com/think/topics/multiagent-system).', 'score': 0.69399214, 'raw_content': None}, {'url': 'https://www.designveloper.com/blog/what-is-langgraph/', 'title': 'What is LangGraph? Key Concepts, Use Cases, and How to Get ...', 'content': 'In other words, for anyone wondering what is LangGraph, it is a stateful orchestration framework for AI agents that gives developers more control over how those agents interact and solve problems. LangGraph allows more complex, multi-agent interactions and decision-making processes than linear pipelines by modelling workflows as graphs (with the option of loops or cyclical flows). LangGraph is particularly suitable to support multi-agent systems due to its graph design and statefulness. Graph structures provide flexibility in workflow design; state management makes sure that context is maintained; coordination and control flow tools enable complex logic and multi-agent systems; and built-in capabilities such as persistence, streaming, and human-in-loop support make it feasible in real-world, error-tolerant systems. Our team delivers agentic apps that use LangGraph for clear control flow, shared state, and human-in-the-loop checks.', 'score': 0.683948, 'raw_content': None}, {'url': 'https://www.cohorte.co/blog/unleashing-the-power-of-langgraph-an-introduction-to-the-future-of-ai-workflows', 'title': 'Unleashing the Power of LangGraph: An Introduction to ... - Cohorte', 'content': \"Then it's time to meet LangGraph, an innovative library that makes building stateful, multi-agent applications with Large Language Models (LLMs) not only feasible but exciting and efficient. LangGraph is like the ultimate AI workflow playground—it’s a library that lets you design how AI agents behave, collaborate, and respond to changes in real time. This makes LangGraph perfect for creating reliable AI systems that need to be trusted in business settings—where AI can do most of the work, but a human keeps an eye on the really critical decisions. LangGraph goes beyond those linear chains—it lets you create decision-making loops, pauses for human checks, and elaborate multi-agent setups. From multi-agent systems to persistent workflows with human approval, LangGraph is about making AI applications that are both smart and sustainable.\", 'score': 0.6072213, 'raw_content': None}, {'url': 'https://www.youtube.com/watch?v=J5d1l6xgQBc', 'title': 'Introduction to LangGraph: A Quick Dive into Core Concepts', 'content': \"Introduction to LangGraph: A Quick Dive into Core Concepts\\nCoding Crash Courses\\n16900 subscribers\\n670 likes\\n21914 views\\n27 May 2024\\nIn this video, we'll explore LangGraph, a powerful tool that enables agentic workflows with language learning models (LLMs) through cycles, enhancing efficiency and performance. Built on top of LangChain, LangGraph leverages its robust foundation to streamline processes and facilitate seamless integration. Whether you're a beginner or an experienced user, this crash course will guide you through the core concepts of LangGraph, helping you understand its capabilities and how it can be applied to your projects. Let's dive in and unlock the potential of LangGraph together!\\n\\nCode: https://github.com/Coding-Crashkurse/LangGraph-Tutorial\\n\\nTimestamps:\\n0:00 Basic Concepts of LangGraph\\n2:02 Nodes & Edges\\n7:19 Conditional Edges\\n10:46 Cycles\\n14:04 Real World Agent with LLM\\n\\n#langchain #langgraph #agents\\n76 comments\\n\", 'score': 0.5683445, 'raw_content': None}], 'response_time': 1.91, 'request_id': '56db4679-0ce3-4901-885f-f8abf9d09b04'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "tavily_search = TavilySearch(tavily_api_key=tavily_api_key)\n",
    "\n",
    "structure_llm = llm.with_structured_output(SearchQuery)\n",
    "search_query = structure_llm.invoke([search_instructions]+state[\"messages\"])\n",
    "search_docs = tavily_search.invoke(search_query.search_query)\n",
    "\n",
    "print(search_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c02b94b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://www.linkedin.com/pulse/exploring-langgraph-my-first-steps-core-concepts-illangarathne-eezlc', 'title': 'Exploring LangGraph: My First Steps, Core Concepts, and Design ...', 'content': 'LangGraph represents a paradigm shift from prompt chaining to contextual orchestration. By visualizing agent logic as a graph: Developers gain', 'score': 0.7339103, 'raw_content': None}, {'url': 'https://www.ibm.com/think/topics/langgraph', 'title': 'What is LangGraph? - IBM', 'content': '*   [Overview](https://www.ibm.com/think/topics/ai-agents#7281535) *   [Overview](https://www.ibm.com/think/topics/components-of-ai-agents#498277090) *   [Learning](https://www.ibm.com/think/topics/ai-agent-learning#498277087) *   [Tutorial: LangGraph ReAct agent](https://www.ibm.com/think/tutorials/deploy-langgraph-react-agent-manage-it-support-tickets-watsonx-ai#1287801557) *   [Overview](https://www.ibm.com/think/topics/ai-agent-protocols#1509394340) *   [Tutorial: LangGraph ReAct agent](https://www.ibm.com/think/tutorials/deploy-langgraph-react-agent-manage-it-support-tickets-watsonx-ai#80364620) *   [Overview](https://www.ibm.com/think/insights/ai-agent-governance#1268897081) *   [Overview](https://www.ibm.com/think/topics/ai-agent-use-cases#257779831) *   [Human resources](https://www.ibm.com/think/topics/ai-agents-in-human-resources#257779835) LangGraph, created by [LangChain](https://www.ibm.com/think/topics/langchain), is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an [AI agent workflow](https://www.ibm.com/think/topics/ai-agents). LangGraph is also built on several key technologies, including [LangChain,](https://www.ibm.com/think/topics/langchain) a Python framework for building AI applications. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including [chatbots](https://www.ibm.com/think/topics/chatbots), state graphs and [other agent-based systems](https://www.ibm.com/think/topics/multiagent-system).', 'score': 0.69399214, 'raw_content': None}, {'url': 'https://www.designveloper.com/blog/what-is-langgraph/', 'title': 'What is LangGraph? Key Concepts, Use Cases, and How to Get ...', 'content': 'In other words, for anyone wondering what is LangGraph, it is a stateful orchestration framework for AI agents that gives developers more control over how those agents interact and solve problems. LangGraph allows more complex, multi-agent interactions and decision-making processes than linear pipelines by modelling workflows as graphs (with the option of loops or cyclical flows). LangGraph is particularly suitable to support multi-agent systems due to its graph design and statefulness. Graph structures provide flexibility in workflow design; state management makes sure that context is maintained; coordination and control flow tools enable complex logic and multi-agent systems; and built-in capabilities such as persistence, streaming, and human-in-loop support make it feasible in real-world, error-tolerant systems. Our team delivers agentic apps that use LangGraph for clear control flow, shared state, and human-in-the-loop checks.', 'score': 0.683948, 'raw_content': None}, {'url': 'https://www.cohorte.co/blog/unleashing-the-power-of-langgraph-an-introduction-to-the-future-of-ai-workflows', 'title': 'Unleashing the Power of LangGraph: An Introduction to ... - Cohorte', 'content': \"Then it's time to meet LangGraph, an innovative library that makes building stateful, multi-agent applications with Large Language Models (LLMs) not only feasible but exciting and efficient. LangGraph is like the ultimate AI workflow playground—it’s a library that lets you design how AI agents behave, collaborate, and respond to changes in real time. This makes LangGraph perfect for creating reliable AI systems that need to be trusted in business settings—where AI can do most of the work, but a human keeps an eye on the really critical decisions. LangGraph goes beyond those linear chains—it lets you create decision-making loops, pauses for human checks, and elaborate multi-agent setups. From multi-agent systems to persistent workflows with human approval, LangGraph is about making AI applications that are both smart and sustainable.\", 'score': 0.6072213, 'raw_content': None}, {'url': 'https://www.youtube.com/watch?v=J5d1l6xgQBc', 'title': 'Introduction to LangGraph: A Quick Dive into Core Concepts', 'content': \"Introduction to LangGraph: A Quick Dive into Core Concepts\\nCoding Crash Courses\\n16900 subscribers\\n670 likes\\n21914 views\\n27 May 2024\\nIn this video, we'll explore LangGraph, a powerful tool that enables agentic workflows with language learning models (LLMs) through cycles, enhancing efficiency and performance. Built on top of LangChain, LangGraph leverages its robust foundation to streamline processes and facilitate seamless integration. Whether you're a beginner or an experienced user, this crash course will guide you through the core concepts of LangGraph, helping you understand its capabilities and how it can be applied to your projects. Let's dive in and unlock the potential of LangGraph together!\\n\\nCode: https://github.com/Coding-Crashkurse/LangGraph-Tutorial\\n\\nTimestamps:\\n0:00 Basic Concepts of LangGraph\\n2:02 Nodes & Edges\\n7:19 Conditional Edges\\n10:46 Cycles\\n14:04 Real World Agent with LLM\\n\\n#langchain #langgraph #agents\\n76 comments\\n\", 'score': 0.5683445, 'raw_content': None}]\n"
     ]
    }
   ],
   "source": [
    "print(search_docs['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c6a632a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://www.linkedin.com/pulse/exploring-langgraph-my-first-steps-core-concepts-illangarathne-eezlc', 'title': 'Exploring LangGraph: My First Steps, Core Concepts, and Design ...', 'content': 'LangGraph represents a paradigm shift from prompt chaining to contextual orchestration. By visualizing agent logic as a graph: Developers gain', 'score': 0.7339103, 'raw_content': None}\n",
      "{'url': 'https://www.ibm.com/think/topics/langgraph', 'title': 'What is LangGraph? - IBM', 'content': '*   [Overview](https://www.ibm.com/think/topics/ai-agents#7281535) *   [Overview](https://www.ibm.com/think/topics/components-of-ai-agents#498277090) *   [Learning](https://www.ibm.com/think/topics/ai-agent-learning#498277087) *   [Tutorial: LangGraph ReAct agent](https://www.ibm.com/think/tutorials/deploy-langgraph-react-agent-manage-it-support-tickets-watsonx-ai#1287801557) *   [Overview](https://www.ibm.com/think/topics/ai-agent-protocols#1509394340) *   [Tutorial: LangGraph ReAct agent](https://www.ibm.com/think/tutorials/deploy-langgraph-react-agent-manage-it-support-tickets-watsonx-ai#80364620) *   [Overview](https://www.ibm.com/think/insights/ai-agent-governance#1268897081) *   [Overview](https://www.ibm.com/think/topics/ai-agent-use-cases#257779831) *   [Human resources](https://www.ibm.com/think/topics/ai-agents-in-human-resources#257779835) LangGraph, created by [LangChain](https://www.ibm.com/think/topics/langchain), is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an [AI agent workflow](https://www.ibm.com/think/topics/ai-agents). LangGraph is also built on several key technologies, including [LangChain,](https://www.ibm.com/think/topics/langchain) a Python framework for building AI applications. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including [chatbots](https://www.ibm.com/think/topics/chatbots), state graphs and [other agent-based systems](https://www.ibm.com/think/topics/multiagent-system).', 'score': 0.69399214, 'raw_content': None}\n",
      "{'url': 'https://www.designveloper.com/blog/what-is-langgraph/', 'title': 'What is LangGraph? Key Concepts, Use Cases, and How to Get ...', 'content': 'In other words, for anyone wondering what is LangGraph, it is a stateful orchestration framework for AI agents that gives developers more control over how those agents interact and solve problems. LangGraph allows more complex, multi-agent interactions and decision-making processes than linear pipelines by modelling workflows as graphs (with the option of loops or cyclical flows). LangGraph is particularly suitable to support multi-agent systems due to its graph design and statefulness. Graph structures provide flexibility in workflow design; state management makes sure that context is maintained; coordination and control flow tools enable complex logic and multi-agent systems; and built-in capabilities such as persistence, streaming, and human-in-loop support make it feasible in real-world, error-tolerant systems. Our team delivers agentic apps that use LangGraph for clear control flow, shared state, and human-in-the-loop checks.', 'score': 0.683948, 'raw_content': None}\n",
      "{'url': 'https://www.cohorte.co/blog/unleashing-the-power-of-langgraph-an-introduction-to-the-future-of-ai-workflows', 'title': 'Unleashing the Power of LangGraph: An Introduction to ... - Cohorte', 'content': \"Then it's time to meet LangGraph, an innovative library that makes building stateful, multi-agent applications with Large Language Models (LLMs) not only feasible but exciting and efficient. LangGraph is like the ultimate AI workflow playground—it’s a library that lets you design how AI agents behave, collaborate, and respond to changes in real time. This makes LangGraph perfect for creating reliable AI systems that need to be trusted in business settings—where AI can do most of the work, but a human keeps an eye on the really critical decisions. LangGraph goes beyond those linear chains—it lets you create decision-making loops, pauses for human checks, and elaborate multi-agent setups. From multi-agent systems to persistent workflows with human approval, LangGraph is about making AI applications that are both smart and sustainable.\", 'score': 0.6072213, 'raw_content': None}\n",
      "{'url': 'https://www.youtube.com/watch?v=J5d1l6xgQBc', 'title': 'Introduction to LangGraph: A Quick Dive into Core Concepts', 'content': \"Introduction to LangGraph: A Quick Dive into Core Concepts\\nCoding Crash Courses\\n16900 subscribers\\n670 likes\\n21914 views\\n27 May 2024\\nIn this video, we'll explore LangGraph, a powerful tool that enables agentic workflows with language learning models (LLMs) through cycles, enhancing efficiency and performance. Built on top of LangChain, LangGraph leverages its robust foundation to streamline processes and facilitate seamless integration. Whether you're a beginner or an experienced user, this crash course will guide you through the core concepts of LangGraph, helping you understand its capabilities and how it can be applied to your projects. Let's dive in and unlock the potential of LangGraph together!\\n\\nCode: https://github.com/Coding-Crashkurse/LangGraph-Tutorial\\n\\nTimestamps:\\n0:00 Basic Concepts of LangGraph\\n2:02 Nodes & Edges\\n7:19 Conditional Edges\\n10:46 Cycles\\n14:04 Real World Agent with LLM\\n\\n#langchain #langgraph #agents\\n76 comments\\n\", 'score': 0.5683445, 'raw_content': None}\n"
     ]
    }
   ],
   "source": [
    "for doc in search_docs['results']:\n",
    "    print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d8f4c296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Document href=\"https://www.linkedin.com/pulse/exploring-langgraph-my-first-steps-core-concepts-illangarathne-eezlc\"/>\n",
      "LangGraph represents a paradigm shift from prompt chaining to contextual orchestration. By visualizing agent logic as a graph: Developers gain\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.ibm.com/think/topics/langgraph\"/>\n",
      "*   [Overview](https://www.ibm.com/think/topics/ai-agents#7281535) *   [Overview](https://www.ibm.com/think/topics/components-of-ai-agents#498277090) *   [Learning](https://www.ibm.com/think/topics/ai-agent-learning#498277087) *   [Tutorial: LangGraph ReAct agent](https://www.ibm.com/think/tutorials/deploy-langgraph-react-agent-manage-it-support-tickets-watsonx-ai#1287801557) *   [Overview](https://www.ibm.com/think/topics/ai-agent-protocols#1509394340) *   [Tutorial: LangGraph ReAct agent](https://www.ibm.com/think/tutorials/deploy-langgraph-react-agent-manage-it-support-tickets-watsonx-ai#80364620) *   [Overview](https://www.ibm.com/think/insights/ai-agent-governance#1268897081) *   [Overview](https://www.ibm.com/think/topics/ai-agent-use-cases#257779831) *   [Human resources](https://www.ibm.com/think/topics/ai-agents-in-human-resources#257779835) LangGraph, created by [LangChain](https://www.ibm.com/think/topics/langchain), is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an [AI agent workflow](https://www.ibm.com/think/topics/ai-agents). LangGraph is also built on several key technologies, including [LangChain,](https://www.ibm.com/think/topics/langchain) a Python framework for building AI applications. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including [chatbots](https://www.ibm.com/think/topics/chatbots), state graphs and [other agent-based systems](https://www.ibm.com/think/topics/multiagent-system).\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.designveloper.com/blog/what-is-langgraph/\"/>\n",
      "In other words, for anyone wondering what is LangGraph, it is a stateful orchestration framework for AI agents that gives developers more control over how those agents interact and solve problems. LangGraph allows more complex, multi-agent interactions and decision-making processes than linear pipelines by modelling workflows as graphs (with the option of loops or cyclical flows). LangGraph is particularly suitable to support multi-agent systems due to its graph design and statefulness. Graph structures provide flexibility in workflow design; state management makes sure that context is maintained; coordination and control flow tools enable complex logic and multi-agent systems; and built-in capabilities such as persistence, streaming, and human-in-loop support make it feasible in real-world, error-tolerant systems. Our team delivers agentic apps that use LangGraph for clear control flow, shared state, and human-in-the-loop checks.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.cohorte.co/blog/unleashing-the-power-of-langgraph-an-introduction-to-the-future-of-ai-workflows\"/>\n",
      "Then it's time to meet LangGraph, an innovative library that makes building stateful, multi-agent applications with Large Language Models (LLMs) not only feasible but exciting and efficient. LangGraph is like the ultimate AI workflow playground—it’s a library that lets you design how AI agents behave, collaborate, and respond to changes in real time. This makes LangGraph perfect for creating reliable AI systems that need to be trusted in business settings—where AI can do most of the work, but a human keeps an eye on the really critical decisions. LangGraph goes beyond those linear chains—it lets you create decision-making loops, pauses for human checks, and elaborate multi-agent setups. From multi-agent systems to persistent workflows with human approval, LangGraph is about making AI applications that are both smart and sustainable.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.youtube.com/watch?v=J5d1l6xgQBc\"/>\n",
      "Introduction to LangGraph: A Quick Dive into Core Concepts\n",
      "Coding Crash Courses\n",
      "16900 subscribers\n",
      "670 likes\n",
      "21914 views\n",
      "27 May 2024\n",
      "In this video, we'll explore LangGraph, a powerful tool that enables agentic workflows with language learning models (LLMs) through cycles, enhancing efficiency and performance. Built on top of LangChain, LangGraph leverages its robust foundation to streamline processes and facilitate seamless integration. Whether you're a beginner or an experienced user, this crash course will guide you through the core concepts of LangGraph, helping you understand its capabilities and how it can be applied to your projects. Let's dive in and unlock the potential of LangGraph together!\n",
      "\n",
      "Code: https://github.com/Coding-Crashkurse/LangGraph-Tutorial\n",
      "\n",
      "Timestamps:\n",
      "0:00 Basic Concepts of LangGraph\n",
      "2:02 Nodes & Edges\n",
      "7:19 Conditional Edges\n",
      "10:46 Cycles\n",
      "14:04 Real World Agent with LLM\n",
      "\n",
      "#langchain #langgraph #agents\n",
      "76 comments\n",
      "\n",
      "</Document>\n"
     ]
    }
   ],
   "source": [
    "formatted = \"\\n\\n---\\n\\n\".join(\n",
    "    [\n",
    "        f'<Document href=\"{doc.get(\"url\", \"#\")}\"/>\\n{doc.get(\"content\", \"\")}\\n</Document>'\n",
    "        for doc in search_docs['results']\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839a5b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search_web(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf690c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"context\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9d47570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research_and_analyst.prompt_lib.prompt_locator import (\n",
    "    CREATE_ANALYSTS_PROMPT,\n",
    "    INTRO_CONCLUSION_INSTRUCTIONS,\n",
    "    REPORT_WRITER_INSTRUCTIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40b6f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\n",
      "\n",
      "1. First, review the research topic:\n",
      "\n",
      "finance\n",
      "\n",
      "        \n",
      "2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts: \n",
      "\n",
      "give the real info\n",
      "\n",
      "    \n",
      "3. Determine the most interesting themes based upon documents and / or feedback above.\n",
      "                    \n",
      "4. Pick the top 3 themes.\n",
      "\n",
      "5. Assign one analyst to each theme.\n"
     ]
    }
   ],
   "source": [
    "print(CREATE_ANALYSTS_PROMPT.render(topic=\"finance\",\n",
    "                                    max_analysts=3,\n",
    "                                    human_analyst_feedback=\"give the real info\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a64aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wikipedia(state:InterviewState):\n",
    "    \"\"\"\n",
    "    Retrieve data from wiki\n",
    "    \"\"\"\n",
    "    # Search query\n",
    "    structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    search_query = structured_llm.invoke([search_instructions]+state['messages'])\n",
    "    \n",
    "    print(\"*******************************\")\n",
    "    print(search_query)\n",
    "    \n",
    "    # Search\n",
    "    search_docs = WikipediaLoader(query=search_query.search_query).load()\n",
    "\n",
    "     # Format\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in search_docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"context\": [formatted_search_docs]} \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edfb131",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"max_num_turns\":2,\"context\":[],\"analyst\":analyst,\"interview\":\"\",\"section\":[],'messages': [AIMessage(content=\"Hello, my name is Alex Thompson, and I'm an analyst interested in understanding the strategic implications of adopting Langgraph for businesses. I'm particularly keen on how this framework can drive innovation and support digital transformation initiatives. Thank you for taking the time to speak with me today, Michael. \\n\\nTo start, could you explain what Langgraph is and why it's becoming a significant consideration for businesses looking to innovate?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 224, 'total_tokens': 303, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CPRmMT7ufhFyYLhMtNpeguI9W2y6O', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--827b799b-ccb9-422c-a444-402d7ddc4550-0', usage_metadata={'input_tokens': 224, 'output_tokens': 79, 'total_tokens': 303, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83fd952",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search_wikipedia(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83262f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_docs = WikipediaLoader(query='Langgraph framework benefits',load_all_available_meta=True).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82687a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf9f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_instructions = \"\"\"You are an expert being interviewed by an analyst.\n",
    "\n",
    "Here is analyst area of focus: {goals}. \n",
    "        \n",
    "You goal is to answer a question posed by the interviewer.\n",
    "\n",
    "To answer question, use this context:\n",
    "        \n",
    "{context}\n",
    "\n",
    "When answering questions, follow these guidelines:\n",
    "        \n",
    "1. Use only the information provided in the context. \n",
    "        \n",
    "2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\n",
    "\n",
    "3. The context contain sources at the topic of each individual document.\n",
    "\n",
    "4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1]. \n",
    "\n",
    "5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\n",
    "        \n",
    "6. If the source is: <Document source=\"assistant/docs/llama3_1.pdf\" page=\"7\"/>' then just list: \n",
    "        \n",
    "[1] assistant/docs/llama3_1.pdf, page 7 \n",
    "        \n",
    "And skip the addition of the brackets as well as the Document source preamble in your citation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a281deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state:InterviewState):\n",
    "   \n",
    "    \"\"\" Node to answer a question \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    analyst = state[\"analyst\"]\n",
    "    messages = state[\"messages\"]\n",
    "    context = state[\"context\"]\n",
    "\n",
    "    # Answer question\n",
    "    system_message = answer_instructions.format(goals=analyst.persona, context=context)\n",
    "    answer = llm.invoke([SystemMessage(content=system_message)]+messages)\n",
    "            \n",
    "    # Name the message as coming from the expert\n",
    "    answer.name = \"expert\"\n",
    "    \n",
    "    # Append it to state\n",
    "    return {\"messages\": [answer]}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983ad150",
   "metadata": {},
   "source": [
    "how many analyst we were doing to be create:\n",
    "4\n",
    "\n",
    "max_trun:2\n",
    "\n",
    "means if atleast 2 expert are giving ans then we can save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d88f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_messages(state: InterviewState, \n",
    "                   name: str = \"expert\"):\n",
    "\n",
    "    \"\"\" Route between question and answer \"\"\"\n",
    "    \n",
    "    # Get messages\n",
    "    messages = state[\"messages\"]\n",
    "    max_num_turns = state.get('max_num_turns',2)\n",
    "\n",
    "    # Check the number of expert answers \n",
    "    num_responses = len(\n",
    "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
    "    )\n",
    "\n",
    "    # End if expert has answered more than the max turns\n",
    "    if num_responses >= max_num_turns:\n",
    "        return 'save_interview'\n",
    "\n",
    "    # This router is run after each question - answer pair \n",
    "    # Get the last question asked to check if it signals the end of discussion\n",
    "    last_question = messages[-2]\n",
    "    \n",
    "    if \"Thank you so much for your help\" in last_question.content:\n",
    "        return 'save_interview'\n",
    "    \n",
    "    return \"ask_question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a6354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_interview(state: InterviewState):\n",
    "    \n",
    "    \"\"\" Save interviews \"\"\"\n",
    "\n",
    "    # Get messages\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Convert interview to a string\n",
    "    interview = get_buffer_string(messages)\n",
    "    \n",
    "    # Save to interviews key\n",
    "    return {\"interview\": interview}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8306476",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_writer_instructions = \"\"\"You are an expert technical writer. \n",
    "            \n",
    "Your task is to create a short, easily digestible section of a report based on a set of source documents.\n",
    "\n",
    "1. Analyze the content of the source documents: \n",
    "- The name of each source document is at the start of the document, with the <Document tag.\n",
    "        \n",
    "2. Create a report structure using markdown formatting:\n",
    "- Use ## for the section title\n",
    "- Use ### for sub-section headers\n",
    "        \n",
    "3. Write the report following this structure:\n",
    "a. Title (## header)\n",
    "b. Summary (### header)\n",
    "c. Sources (### header)\n",
    "\n",
    "4. Make your title engaging based upon the focus area of the analyst: \n",
    "{focus}\n",
    "\n",
    "5. For the summary section:\n",
    "- Set up summary with general background / context related to the focus area of the analyst\n",
    "- Emphasize what is novel, interesting, or surprising about insights gathered from the interview\n",
    "- Create a numbered list of source documents, as you use them\n",
    "- Do not mention the names of interviewers or experts\n",
    "- Aim for approximately 400 words maximum\n",
    "- Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\n",
    "        \n",
    "6. In the Sources section:\n",
    "- Include all sources used in your report\n",
    "- Provide full links to relevant websites or specific document paths\n",
    "- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\n",
    "- It will look like:\n",
    "\n",
    "### Sources\n",
    "[1] Link or Document name\n",
    "[2] Link or Document name\n",
    "\n",
    "7. Be sure to combine sources. For example this is not correct:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "[4] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "\n",
    "There should be no redundant sources. It should simply be:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "        \n",
    "8. Final review:\n",
    "- Ensure the report follows the required structure\n",
    "- Include no preamble before the title of the report\n",
    "- Check that all guidelines have been followed\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a50dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_section(state: InterviewState):\n",
    "\n",
    "    \"\"\" Node to answer a question \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    interview = state[\"interview\"]\n",
    "    context = state[\"context\"]\n",
    "    analyst = state[\"analyst\"]\n",
    "   \n",
    "    # Write section using either the gathered source docs from interview (context) or the interview itself (interview)\n",
    "    system_message = section_writer_instructions.format(focus=analyst.description)\n",
    "    section = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\"Use this source to write your section: {context}\")]) \n",
    "                \n",
    "    # Append it to state\n",
    "    return {\"sections\": [section.content]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_builder = StateGraph(InterviewState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dde8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_builder.add_node(\"ask_question\",generation_question)\n",
    "interview_builder.add_node(\"search_web\",search_web)\n",
    "interview_builder.add_node(\"search_wikipedia\",search_wikipedia)\n",
    "interview_builder.add_node(\"generate_answer\",generate_answer)\n",
    "interview_builder.add_node(\"save_interview\",save_interview)\n",
    "interview_builder.add_node(\"write_section\",write_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_builder.add_edge(START, \"ask_question\")\n",
    "interview_builder.add_edge(\"ask_question\",\"search_web\")\n",
    "interview_builder.add_edge(\"ask_question\",\"search_wikipedia\")\n",
    "interview_builder.add_edge(\"search_web\",\"generate_answer\")\n",
    "interview_builder.add_edge(\"search_wikipedia\",\"generate_answer\")\n",
    "interview_builder.add_conditional_edges(\"generate_answer\",\n",
    "                           route_messages,\n",
    "                           [\"ask_question\",\n",
    "                            \"save_interview\"])\n",
    "interview_builder.add_edge(\"save_interview\",\"write_section\")\n",
    "interview_builder.add_edge(\"write_section\",END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d9ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name = \"Conduct Interview\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(interview_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2da908",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst.persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db214534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdde6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(\"So you said you were writing an article on MCP?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a2c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "interview = interview_graph.invoke({\"analyst\": analyst, \"messages\": messages, \"max_num_turns\": 2}, thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c46c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(interview['sections'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70355645",
   "metadata": {},
   "source": [
    "## third Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cf6c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List, Annotated\n",
    "import operator\n",
    "class ResearchGraphState(TypedDict):\n",
    "    topic: str # Research topic\n",
    "    max_analysts: int # Number of analysts\n",
    "    human_analyst_feedback: str # Human feedback\n",
    "    analysts: List[Analyst] # Analyst asking questions\n",
    "    sections: Annotated[list, operator.add] # Send() API key\n",
    "    introduction: str # Introduction for the final report\n",
    "    content: str # Content for the final report\n",
    "    conclusion: str # Conclusion for the final report\n",
    "    final_report: str # Final report\n",
    "    \n",
    "# class InterviewState(MessagesState):\n",
    "#     max_num_turns: int # Number turns of conversation\n",
    "#     context: Annotated[list, operator.add] # Source docs\n",
    "#     analyst: Analyst # Analyst asking questions\n",
    "#     interview: str # Interview transcript\n",
    "#     sections: list # Final key we duplicate in outer state for Send() API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae420268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b8b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_all_interviews(state:ResearchGraphState):\n",
    "    \"\"\" This is the \"map\" step where we run each interview sub-graph using Send API \"\"\" \n",
    "    \n",
    "    #check if human feedback\n",
    "    human_analyst_feedback=state.get('human_analyst_feedback')\n",
    "    if human_analyst_feedback:\n",
    "        # Return to create_analysts\n",
    "        return \"create_analysts\"\n",
    "    \n",
    "    # Otherwise kick off interviews in parallel via Send() API\n",
    "    else:\n",
    "        topic = state[\"topic\"]\n",
    "        return [Send(\"conduct_interview\", {\"analyst\": analyst,\n",
    "                                        \"messages\": [HumanMessage(\n",
    "                                            content=f\"So you said you were writing an article on {topic}?\"\n",
    "                                        )\n",
    "                                                ]}) for analyst in state[\"analysts\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e497a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_report(state:ResearchGraphState):\n",
    "#     \"\"\"_summary_\n",
    "\n",
    "#     Args:\n",
    "#         state (ResearchGraphState): _description_\n",
    "#     \"\"\"\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1753ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_writer_instructions = \"\"\"You are a technical writer creating a report on this overall topic: \n",
    "\n",
    "{topic}\n",
    "    \n",
    "You have a team of analysts. Each analyst has done two things: \n",
    "\n",
    "1. They conducted an interview with an expert on a specific sub-topic.\n",
    "2. They write up their finding into a memo.\n",
    "\n",
    "Your task: \n",
    "\n",
    "1. You will be given a collection of memos from your analysts.\n",
    "2. Think carefully about the insights from each memo.\n",
    "3. Consolidate these into a crisp overall summary that ties together the central ideas from all of the memos. \n",
    "4. Summarize the central points in each memo into a cohesive single narrative.\n",
    "\n",
    "To format your report:\n",
    " \n",
    "1. Use markdown formatting. \n",
    "2. Include no pre-amble for the report.\n",
    "3. Use no sub-heading. \n",
    "4. Start your report with a single title header: ## Insights\n",
    "5. Do not mention any analyst names in your report.\n",
    "6. Preserve any citations in the memos, which will be annotated in brackets, for example [1] or [2].\n",
    "7. Create a final, consolidated list of sources and add to a Sources section with the `## Sources` header.\n",
    "8. List your sources in order and do not repeat.\n",
    "\n",
    "[1] Source 1\n",
    "[2] Source 2\n",
    "\n",
    "Here are the memos from your analysts to build your report from: \n",
    "\n",
    "{context}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c920f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_report(state: ResearchGraphState):\n",
    "    # Full set of sections\n",
    "    sections = state[\"sections\"]\n",
    "    topic = state[\"topic\"]\n",
    "\n",
    "    # Concat all sections together\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "    \n",
    "    # Summarize the sections into a final report\n",
    "    system_message = report_writer_instructions.format(topic=topic, context=formatted_str_sections)    \n",
    "    report = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\"Write a report based upon these memos.\")]) \n",
    "    return {\"content\": report.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcba2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_conclusion_instructions = \"\"\"You are a technical writer finishing a report on {topic}\n",
    "\n",
    "You will be given all of the sections of the report.\n",
    "\n",
    "You job is to write a crisp and compelling introduction or conclusion section.\n",
    "\n",
    "The user will instruct you whether to write the introduction or conclusion.\n",
    "\n",
    "Include no pre-amble for either section.\n",
    "\n",
    "Target around 100 words, crisply previewing (for introduction) or recapping (for conclusion) all of the sections of the report.\n",
    "\n",
    "Use markdown formatting. \n",
    "\n",
    "For your introduction, create a compelling title and use the # header for the title.\n",
    "\n",
    "For your introduction, use ## Introduction as the section header. \n",
    "\n",
    "For your conclusion, use ## Conclusion as the section header.\n",
    "\n",
    "Here are the sections to reflect on for writing: {formatted_str_sections}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_introduction(state: ResearchGraphState):\n",
    "    # Full set of sections\n",
    "    sections = state[\"sections\"]\n",
    "    topic = state[\"topic\"]\n",
    "\n",
    "    # Concat all sections together\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "    \n",
    "    # Summarize the sections into a final report\n",
    "    \n",
    "    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)    \n",
    "    intro = llm.invoke([instructions]+[HumanMessage(content=f\"Write the report introduction\")]) \n",
    "    return {\"introduction\": intro.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_conclusion(state: ResearchGraphState):\n",
    "    # Full set of sections\n",
    "    sections = state[\"sections\"]\n",
    "    topic = state[\"topic\"]\n",
    "\n",
    "    # Concat all sections together\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "    \n",
    "    # Summarize the sections into a final report\n",
    "    \n",
    "    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)    \n",
    "    conclusion = llm.invoke([instructions]+[HumanMessage(content=f\"Write the report conclusion\")]) \n",
    "    return {\"conclusion\": conclusion.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aa6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_report(state: ResearchGraphState):\n",
    "    \"\"\" The is the \"reduce\" step where we gather all the sections, combine them, and reflect on them to write the intro/conclusion \"\"\"\n",
    "    # Save full final report\n",
    "    content = state[\"content\"]\n",
    "    if content.startswith(\"## Insights\"):\n",
    "        content = content.strip(\"## Insights\")\n",
    "    if \"## Sources\" in content:\n",
    "        try:\n",
    "            content, sources = content.split(\"\\n## Sources\\n\")\n",
    "        except:\n",
    "            sources = None\n",
    "    else:\n",
    "        sources = None\n",
    "\n",
    "    final_report = state[\"introduction\"] + \"\\n\\n---\\n\\n\" + content + \"\\n\\n---\\n\\n\" + state[\"conclusion\"]\n",
    "    if sources is not None:\n",
    "        final_report += \"\\n\\n## Sources\\n\" + sources\n",
    "    return {\"final_report\": final_report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36abd58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes and edges \n",
    "builder = StateGraph(ResearchGraphState)\n",
    "builder.add_node(\"create_analysts\", create_analyst)\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "builder.add_node(\"conduct_interview\", interview_builder.compile())\n",
    "builder.add_node(\"write_report\",write_report)\n",
    "builder.add_node(\"write_introduction\",write_introduction)\n",
    "builder.add_node(\"write_conclusion\",write_conclusion)\n",
    "builder.add_node(\"finalize_report\",finalize_report)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"create_analysts\")\n",
    "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
    "builder.add_conditional_edges(\"human_feedback\", initiate_all_interviews, [\"create_analysts\", \"conduct_interview\"])\n",
    "builder.add_edge(\"conduct_interview\", \"write_report\")\n",
    "builder.add_edge(\"conduct_interview\", \"write_introduction\")\n",
    "builder.add_edge(\"conduct_interview\", \"write_conclusion\")\n",
    "builder.add_edge([\"write_conclusion\", \"write_report\", \"write_introduction\"], \"finalize_report\")\n",
    "builder.add_edge(\"finalize_report\", END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebea3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90315e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile(interrupt_before=['human_feedback'], checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d850f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_analysts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06b47d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"How can generative help us to play the cricket?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da9bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"How can generative AI accelerate drug discovery?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32206ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c24312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the graph until the first interruption\n",
    "for event in graph.stream({\"topic\":topic,\"max_analysts\":max_analysts}, thread, stream_mode=\"values\"):\n",
    "    analysts = event.get('analysts', '')\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_state(thread, {\"human_analyst_feedback\":\"along with the genetive ai in future tell me the future of indian team\"}, as_node=\"human_feedback\")\n",
    "# graph.update_state(thread, {\"human_analyst_feedback\":\"\"}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3654ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the graph until the first interruption\n",
    "for event in graph.stream({\"topic\":topic,\"max_analysts\":max_analysts}, thread, stream_mode=\"values\"):\n",
    "    analysts = event.get('analysts', '')\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c508607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_state(thread, {\"human_analyst_feedback\":\"\"}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0754a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(thread).next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed121a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue\n",
    "for event in graph.stream(None, thread, stream_mode=\"updates\"):\n",
    "    print(\"--Node--\")\n",
    "    node_name = next(iter(event.keys()))\n",
    "    print(node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7aafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b99d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = graph.get_state(thread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = final_state.values.get('final_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9af0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
